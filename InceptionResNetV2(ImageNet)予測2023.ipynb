{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curyumafu/sakana/blob/main/InceptionResNetV2(ImageNet)%E4%BA%88%E6%B8%AC2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "セル 1: インポートと環境変数の設定"
      ],
      "metadata": {
        "id": "Q-_br0O0jc__"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuWzIrNKjIMB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "セル 2: 他のインポート"
      ],
      "metadata": {
        "id": "fk-WaiTGj4Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFont, ImageDraw\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "import IPython\n",
        "from google.colab import output\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n"
      ],
      "metadata": {
        "id": "vOHa5qL9j3Eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1b9629-4fcb-4d68-a6f3-1f099820583f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "セル 3: 定数の定義"
      ],
      "metadata": {
        "id": "ZR3SrJsWkG17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FONT_PATH = '/content/drive/MyDrive/実験III_AI演習（ImageNet）2023/ipaexg.ttf'\n",
        "FONT_SIZE = 20\n",
        "DISPLAY_SIZE = 299\n"
      ],
      "metadata": {
        "id": "ZHGyFoWikK4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "セル 4: ディレクトリの変更とモジュールのインポート"
      ],
      "metadata": {
        "id": "63af9qmxkVlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_colab_dir = \"/content/drive/MyDrive/実験III_AI演習（ImageNet）2023\"\n",
        "os.chdir(_colab_dir)\n",
        "\n",
        "import to_japanese_ilsvrc2012 as toj\n",
        "translator = toj.Ilsvrc2012Japanese()\n"
      ],
      "metadata": {
        "id": "0TBbO466kPKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "セル 5: モデルのロード"
      ],
      "metadata": {
        "id": "ObsajES2kc9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionResNetV2(weights='imagenet')\n"
      ],
      "metadata": {
        "id": "rxCgJJULkZJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e927e41d-7cc3-4b62-b5e5-a36fc11d1ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225209952/225209952 [==============================] - 9s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "セル 6: 関数の定義"
      ],
      "metadata": {
        "id": "dCaNawh1kh6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_add_msg(img, messages):\n",
        "    # フォントの設定\n",
        "    font = ImageFont.truetype(FONT_PATH, FONT_SIZE)\n",
        "    # 描画オブジェクトの作成\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    # メッセージのリストから各メッセージを画像に描画\n",
        "    for i, message in enumerate(messages):\n",
        "        draw.text((0, 10 + i * 20), message, font=font, fill=(255, 255, 255, 0))\n",
        "    return img\n",
        "\n",
        "def run(img_str):\n",
        "    # 画像のデコード\n",
        "    decimg = base64.b64decode(img_str.split(',')[1], validate=True)\n",
        "    decimg = Image.open(BytesIO(decimg))\n",
        "    decimg = np.array(decimg, dtype=np.uint8)\n",
        "    decimg = cv2.cvtColor(decimg, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 画像の前処理\n",
        "    trim_frame = decimg[0 : DISPLAY_SIZE, 0 : DISPLAY_SIZE]\n",
        "    x = image.img_to_array(trim_frame)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    # 画像の予測\n",
        "    preds = model.predict(x, verbose=0)\n",
        "    top_preds = decode_predictions(preds, top=5)[0]\n",
        "\n",
        "    # メッセージの生成\n",
        "    if int(top_preds[0][2] * 100) >= 50:\n",
        "        messages = [f\"TOP{i+1} : {translator.convert(str(pred[1]))} : {int(pred[2]*100)}%\" for i, pred in enumerate(top_preds)]\n",
        "    else:\n",
        "        messages = [\"NONE\"]\n",
        "\n",
        "    # 画像にメッセージを追加\n",
        "    img = Image.fromarray(trim_frame)\n",
        "    img = img_add_msg(img, messages)\n",
        "\n",
        "    # 画像をbase64形式に変換して返す\n",
        "    img = np.array(img)\n",
        "    out_img = cv2.resize(img, (DISPLAY_SIZE, DISPLAY_SIZE))\n",
        "    _, encimg = cv2.imencode(\".jpg\", out_img, [int(cv2.IMWRITE_JPEG_QUALITY), 80])\n",
        "    img_str = \"data:image/jpeg;base64,\" + base64.b64encode(encimg.tobytes()).decode('utf-8')\n",
        "    return IPython.display.JSON({'img_str': img_str})\n",
        "\n",
        "# コールバックの登録\n",
        "output.register_callback('notebook.run', run)\n",
        "\n",
        "def use_cam(quality=0.8):\n",
        "  # JavaScriptコードの定義：ウェブカメラの利用\n",
        "  js = Javascript('''\n",
        "    async function useCam(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "      //video element\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'None';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      //canvas for display. frame rate is depending on display size and jpeg quality.\n",
        "      display_size = 299\n",
        "      const src_canvas = document.createElement('canvas');\n",
        "      src_canvas.width  = display_size;\n",
        "      src_canvas.height = display_size;;\n",
        "      const src_canvasCtx = src_canvas.getContext('2d');\n",
        "      src_canvasCtx.translate(src_canvas.width, 0);\n",
        "      src_canvasCtx.scale(-1, 1);\n",
        "      div.appendChild(src_canvas);\n",
        "\n",
        "      const dst_canvas = document.createElement('canvas');\n",
        "      dst_canvas.width  = src_canvas.width;\n",
        "      dst_canvas.height = src_canvas.height;\n",
        "      const dst_canvasCtx = dst_canvas.getContext('2d');\n",
        "      div.appendChild(dst_canvas);\n",
        "\n",
        "      //exit button\n",
        "      const btn_div = document.createElement('div');\n",
        "      document.body.appendChild(btn_div);\n",
        "      const exit_btn = document.createElement('button');\n",
        "      exit_btn.textContent = 'Exit';\n",
        "      var exit_flg = true\n",
        "      exit_btn.onclick = function() {exit_flg = false};\n",
        "      btn_div.appendChild(exit_btn);\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      var send_num = 0\n",
        "      // loop\n",
        "      _canvasUpdate();\n",
        "      async function _canvasUpdate() {\n",
        "            src_canvasCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight, 0, 0, src_canvas.width, src_canvas.height);\n",
        "            if (send_num<1){\n",
        "                send_num += 1\n",
        "                const img = src_canvas.toDataURL('image/jpeg', quality);\n",
        "                const result = google.colab.kernel.invokeFunction('notebook.run', [img], {});\n",
        "                result.then(function(value) {\n",
        "                    parse = JSON.parse(JSON.stringify(value))[\"data\"]\n",
        "                    parse = JSON.parse(JSON.stringify(parse))[\"application/json\"]\n",
        "                    parse = JSON.parse(JSON.stringify(parse))[\"img_str\"]\n",
        "                    var image = new Image()\n",
        "                    image.src = parse;\n",
        "                    image.onload = function(){dst_canvasCtx.drawImage(image, 0, 0)}\n",
        "                    send_num -= 1\n",
        "                })\n",
        "            }\n",
        "            if (exit_flg){\n",
        "                requestAnimationFrame(_canvasUpdate);\n",
        "            }else{\n",
        "                stream.getVideoTracks()[0].stop();\n",
        "            }\n",
        "      };\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  # ウェブカメラの起動\n",
        "  data = eval_js('useCam({})'.format(quality))\n"
      ],
      "metadata": {
        "id": "b02DApowkgfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "セル 7: ウェブカメラの利用"
      ],
      "metadata": {
        "id": "necA2_yllEm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_cam()\n"
      ],
      "metadata": {
        "id": "BaykFSKJlBI8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "272b5fc5-dc23-41f6-b538-9e8f7b899b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function useCam(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      document.body.appendChild(div);\n",
              "      //video element\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'None';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      //canvas for display. frame rate is depending on display size and jpeg quality.\n",
              "      display_size = 299\n",
              "      const src_canvas = document.createElement('canvas');\n",
              "      src_canvas.width  = display_size;\n",
              "      src_canvas.height = display_size;;\n",
              "      const src_canvasCtx = src_canvas.getContext('2d');\n",
              "      src_canvasCtx.translate(src_canvas.width, 0);\n",
              "      src_canvasCtx.scale(-1, 1);\n",
              "      div.appendChild(src_canvas);\n",
              "\n",
              "      const dst_canvas = document.createElement('canvas');\n",
              "      dst_canvas.width  = src_canvas.width;\n",
              "      dst_canvas.height = src_canvas.height;\n",
              "      const dst_canvasCtx = dst_canvas.getContext('2d');\n",
              "      div.appendChild(dst_canvas);\n",
              "\n",
              "      //exit button\n",
              "      const btn_div = document.createElement('div');\n",
              "      document.body.appendChild(btn_div);\n",
              "      const exit_btn = document.createElement('button');\n",
              "      exit_btn.textContent = 'Exit';\n",
              "      var exit_flg = true\n",
              "      exit_btn.onclick = function() {exit_flg = false};\n",
              "      btn_div.appendChild(exit_btn);\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      var send_num = 0\n",
              "      // loop\n",
              "      _canvasUpdate();\n",
              "      async function _canvasUpdate() {\n",
              "            src_canvasCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight, 0, 0, src_canvas.width, src_canvas.height);\n",
              "            if (send_num<1){\n",
              "                send_num += 1\n",
              "                const img = src_canvas.toDataURL('image/jpeg', quality);\n",
              "                const result = google.colab.kernel.invokeFunction('notebook.run', [img], {});\n",
              "                result.then(function(value) {\n",
              "                    parse = JSON.parse(JSON.stringify(value))[\"data\"]\n",
              "                    parse = JSON.parse(JSON.stringify(parse))[\"application/json\"]\n",
              "                    parse = JSON.parse(JSON.stringify(parse))[\"img_str\"]\n",
              "                    var image = new Image()\n",
              "                    image.src = parse;\n",
              "                    image.onload = function(){dst_canvasCtx.drawImage(image, 0, 0)}\n",
              "                    send_num -= 1\n",
              "                })\n",
              "            }\n",
              "            if (exit_flg){\n",
              "                requestAnimationFrame(_canvasUpdate);\n",
              "            }else{\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "            }\n",
              "      };\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXxVsT1klHuN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}